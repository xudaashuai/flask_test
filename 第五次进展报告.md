
#第五次进展报告

标签（空格分隔）： 进展报告 神经网络 爬虫 深度学习

---
## 1. 微博爬虫进展

将爬虫在`scrapy`上重写，使用微博API进行行信息爬取，平均每分钟可以爬取1500条数据，但是依然存在着一些问题。没有解决微博对单个IP每小时访问API次数的限制，尝试使用代理后发现使用代理时爬取速率急剧下降，每分钟只有100-200条数据，可能原因是代理IP质量不高导致访问速率下降，所以没有使用代理，只是就简单的在爬虫受到IP限制时暂停爬虫，等待一段时间后继续爬取。
目前爬取了大概200多万条质量较高的用户信息数据，下一步将转向爬取微博数据，同时寻找更高效的避免IP限制的方法，和对爬取到的数据进行可视化的处理。

---

##2. 深度学习的学习进展
了解了神经网络的基本概念和发展过程，从最基础的感知器算法开始进行实践编码。
目前理解了感知器算法，并且使用感知器算法实现了 和 和 或 的运算模拟。
了解基础的神经网络，正在进行编码尝试，希望实现一个用神经网络识别简单验证码（学校教务网站登录验证码）的功能。
目前还有几个没有特别理解的点

- 无监督学习感觉有一些过于神奇
- 激活函数到底是个什么东西
- 神经网络的层数和每一层的宽度如何确定

---

##3. 对微软研究院文章的继续阅读
机器之心前几天有一篇[对郑宇博士关于这篇论文的专访](http://www.jiqizhixin.com/article/index/id/2261)帮助我更好的理解了这篇论文。

>如果我们直接使用传统 RNN，要考虑周期性和趋势性，输入的数据必须很长，如果只使用最近两三个小时的数据，就无法体现周期性，也不可能体现趋势性。要体现周期性至少需要 24 小时以上，而趋势性甚至需要几个月的数据，如果把 RNN 作为模型，这么长的数据作为输入，那么 RNN 模型会变的非常大、非常复杂，最后很难训练，效果也不会好。我们也和 LSTM 做了比较发现，我们数据用的帧数更少，结果反而更好。

目前我所理解认识到的简单的神经网络在对数据的空间和时间上的关系没有很好地利用，而这篇论文中要实现的人流预测的数据正是一个在时间和空间上有紧密联系的数据，所以论文采用了基于卷积神经网络的同时，引入了深度残差网络结构，来更好地实现人流预测。
这个文章的另一个重点是在将出租车等数据转换为一个个区域的流量数据，转化为能作为深度学习模型的输入数据。